{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[190 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m /Users/cheencheen/miniforge3/lib/python3.12/site-packages/torch/utils/cpp_extension.py:497: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(msg.format('we could not find ninja.'))\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers\n",
      "  \u001b[31m   \u001b[0m copying xformers/_deprecation_warning.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers\n",
      "  \u001b[31m   \u001b[0m copying xformers/attn_bias_utils.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers\n",
      "  \u001b[31m   \u001b[0m copying xformers/checkpoint.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers\n",
      "  \u001b[31m   \u001b[0m copying xformers/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers\n",
      "  \u001b[31m   \u001b[0m copying xformers/test.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers\n",
      "  \u001b[31m   \u001b[0m copying xformers/utils.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers\n",
      "  \u001b[31m   \u001b[0m copying xformers/_cpp_lib.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers\n",
      "  \u001b[31m   \u001b[0m copying xformers/info.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/triton/vararg_kernel.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/triton/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/triton\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/components\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/residual.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/components\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/components\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/input_projection.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/components\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_mem_eff_attention.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_indexing.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_revnet.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_swiglu.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_merge_attentions.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_tiled_matmul.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/utils.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_nystrom_utils.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_attn_decoding.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_sequence_parallel_fused.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_sddmm.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_sp24.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_core.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/rmsnorm.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/modpar_layers.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/swiglu_op.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/unbind.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/rope_padded.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/seqpar.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/ipc.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/sequence_parallel_fused_ops.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/sp24.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/common.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/differentiable_collectives.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/tiled_matmul.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/indexing.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/profiler\n",
      "  \u001b[31m   \u001b[0m copying xformers/profiler/device_limits.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/profiler\n",
      "  \u001b[31m   \u001b[0m copying xformers/profiler/find_slowest.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/profiler\n",
      "  \u001b[31m   \u001b[0m copying xformers/profiler/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/profiler\n",
      "  \u001b[31m   \u001b[0m copying xformers/profiler/profiler_dcgm_impl.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/profiler\n",
      "  \u001b[31m   \u001b[0m copying xformers/profiler/profiler_dcgm.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/profiler\n",
      "  \u001b[31m   \u001b[0m copying xformers/profiler/api.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/profiler\n",
      "  \u001b[31m   \u001b[0m copying xformers/profiler/profile_analyzer.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/profiler\n",
      "  \u001b[31m   \u001b[0m copying xformers/profiler/profiler.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/profiler\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/sparse\n",
      "  \u001b[31m   \u001b[0m copying xformers/sparse/_csr_ops.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/sparse\n",
      "  \u001b[31m   \u001b[0m copying xformers/sparse/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/sparse\n",
      "  \u001b[31m   \u001b[0m copying xformers/sparse/utils.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/sparse\n",
      "  \u001b[31m   \u001b[0m copying xformers/sparse/blocksparse_tensor.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/sparse\n",
      "  \u001b[31m   \u001b[0m copying xformers/sparse/csr_tensor.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/sparse\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/fused_softmax.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_blocksparse_attn_interface.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_blocksparse_attention.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/bert_padding.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_og.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_interface.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/_sputnik_sparse.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/core.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/fourier_mix.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/scaled_dot_product.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/utils.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/attention_mask.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/attention_patterns.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/sparsity_config.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/base.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks/LRA\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/batch_submit.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks/LRA\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/batch_fetch_results.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks/LRA\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/run_with_submitit.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks/LRA\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks/LRA\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/run_tasks.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks/LRA\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/run_grid_search.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks/LRA\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks/LRA/code\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/code/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks/LRA/code\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/code/model_wrapper.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks/LRA/code\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/code/dataset.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks/LRA/code\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/_triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/k_scaled_index_add.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/_triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/_triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/matmul_perf_model.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/_triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/rope_padded_kernels.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/_triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/tiled_matmul_kernels.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/_triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/k_index_select_cat.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/_triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/rmsnorm_kernels.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/_triton\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/flash3.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/dispatch.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/attn_bias.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/ck.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/common.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/torch_attention_compat.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/ck_decoder.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/flash.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/cutlass.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/ck_splitk.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/triton_splitk.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha/_triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/_triton/splitk_kernels.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha/_triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/_triton/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha/_triton\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/losses\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/losses/cross_entropy.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/losses\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/losses/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/losses\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/layers\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/layers/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/layers\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/layers/patch_embed.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/layers\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/layers/rotary.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/layers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/fwd_ref.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/interface_torch.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/fwd_prefill.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/interface_fa.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/test.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/bench.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/bwd_prefill.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/utils.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/fwd_decode.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/bwd_ref.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/utils\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/pretrained.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/utils\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/generation.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/utils\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/benchmark.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/utils\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/utils\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/distributed.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/utils\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/bigcode.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/gptj.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/opt.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/llama.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/vit.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/btlm.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/baichuan.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/bert.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/falcon.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/gpt_neox.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/gpt.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/activations.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/fused_dense.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/rms_norm.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/layer_norm.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/ops\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/modules\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/modules/embedding.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/modules\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/modules/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/modules\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/modules/mlp.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/modules\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/modules/block.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/modules\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/modules/mha.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/modules\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/ops/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/cross_entropy.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/ops/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/linear.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/ops/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/k_activations.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/ops/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/ops/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/mlp.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/ops/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/rotary.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/ops/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/layer_norm.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/ops/triton\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'xformers._C' extension\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.0-arm64-cpython-312/xformers/csrc/attention\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.0-arm64-cpython-312/xformers/csrc/attention/autograd\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.0-arm64-cpython-312/xformers/csrc/attention/cpu\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.0-arm64-cpython-312/xformers/csrc/sequence_parallel_fused\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.0-arm64-cpython-312/xformers/csrc/sparse24\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.0-arm64-cpython-312/xformers/csrc/swiglu\n",
      "  \u001b[31m   \u001b[0m clang++ -fno-strict-overflow -Wsign-compare -Wunreachable-code -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /Users/cheencheen/miniforge3/include -arch arm64 -fPIC -O2 -isystem /Users/cheencheen/miniforge3/include -arch arm64 -I/private/var/folders/90/wlyndy6j22v9znhdq4r6rqy80000gn/T/pip-install-vq9crank/xformers_f68bfcc366f54c298ec6adf66377fbf3/xformers/csrc -I/Users/cheencheen/miniforge3/lib/python3.12/site-packages/torch/include -I/Users/cheencheen/miniforge3/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/Users/cheencheen/miniforge3/lib/python3.12/site-packages/torch/include/TH -I/Users/cheencheen/miniforge3/lib/python3.12/site-packages/torch/include/THC -I/Users/cheencheen/miniforge3/include/python3.12 -c xformers/csrc/attention/attention.cpp -o build/temp.macosx-11.0-arm64-cpython-312/xformers/csrc/attention/attention.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_clang\\\" -DPYBIND11_STDLIB=\\\"_libcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1002\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "  \u001b[31m   \u001b[0m clang++: error: unsupported option '-fopenmp'\n",
      "  \u001b[31m   \u001b[0m error: command '/usr/bin/clang++' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for xformers\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (xformers)\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU unsloth transformers datasets peft trl accelerate pandas gradio huggingface_hub scikit-learn einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
